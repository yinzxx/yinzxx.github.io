{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c73f08d",
   "metadata": {},
   "source": [
    "## 第一部分：PyTorch深度学习基础知识\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9d783",
   "metadata": {},
   "source": [
    "### 2.2深度学习在实现上的特殊性\n",
    "- 样本量大，通常需要分批（bath）加载\n",
    "- 逐层、模板化搭建网络（卷积层、全连接、LSTM等）\n",
    "- 多样化的损失函数和优化器设计*\n",
    "- GPU的使用\n",
    "- 模块间配合\n",
    "\n",
    "## 2.3PyTorch深度学习模块\n",
    "- 世纪使用根据需要进行修改\n",
    "- 深度学习：搭积木\n",
    "  - 2.3.1基本配置\n",
    "  - 2.3.2数据读入\n",
    "  - 2.3.3模型构建\n",
    "  - 2.3.4损失函数\n",
    "  - 2.3.5优化器\n",
    "  - 2.3.6优化与评估\n",
    "- 边学边练，通过实战案例巩固\n",
    "- 任务：FashionMNIST时装分类\n",
    "- 数据简介：\n",
    "  - 10类图片\n",
    "  - 32*32px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc2194",
   "metadata": {},
   "source": [
    "### 2.\n",
    "- 导入必要的packages\n",
    " - os ,numpy, pandas, torch, torch.nn,torch.optin, torch.utils.data\n",
    "- 配置训练过程中的超参数\n",
    " - batch size,learning rate,max_epochs,num_workers\n",
    "- 配置训练用的硬件设备\n",
    " - cpu ,GPU,\n",
    "- 代码演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6bb457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导包\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8411a9",
   "metadata": {},
   "source": [
    "#### 配置训练环境和超参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a64812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置GPU,这里有两种方式\n",
    "## 一：os.environ\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='0'#这里的0就是第一块显卡\n",
    "# 二：使用“device”,后续对要使用GPU的变量.to(device)即可\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "## 配置其他超参数，batch size,learning rate,max_epochs,num_workers\n",
    "batch_size=256#每次训练数据的量\n",
    "num_workers=4#有多少个线程\n",
    "lr=1e-4#learn rate 每次更新步长\n",
    "epochs=10#总的epochs 训练多少轮\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45963756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.is_available()#我用的cpu版本，emm小的模型也是可以跑的，大家最好下载GPU版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36eff185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "image_size=28\n",
    "data_transform=transforms.Compose([\n",
    "   # transforms.ToPILImage(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb665681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取方式一\n",
    "from torchvision import datasets\n",
    "train_data = datasets.FashionMNIST(root= './',train=True,download=True,transform=data_transform)#train_data是训练集\n",
    "test_data = datasets.FashionMNIST(root='./',train=False,download=True,transform=data_transform)#test_data是测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe344eca",
   "metadata": {},
   "source": [
    "- PyTorch数据读入是通过Dataset+DataLoader的方式完成的，Dataset定义好数据的格式和数据变换形式，DataLoader用iterative的方式不断读入批次数据。\n",
    "\n",
    "  我们可以定义自己的Dataset类来实现灵活的数据读取，定义的类需要继承PyTorch自身的Dataset类。主要包含三个函数：\n",
    "\n",
    "  - __init__: 用于向类中传入外部参数，同时定义样本集\n",
    "\n",
    "  - __getitem__: 用于逐个读取样本集合中的元素，可以进行一定的变换，并将返回训练/验证所需的数据\n",
    "\n",
    "  - __len__: 用于返回数据集的样本数\n",
    "\n",
    "   下面以cifar10数据集为例给出构建Dataset类的方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa1b5e2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./FashionMNIST/fashion-mnist_train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-40643697dd5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./FashionMNIST/fashion-mnist_train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#我也不知到为啥File b'./FashionMNIST/fashion-mnist_train.csv' does not exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./FashionMNIST/fashion-mnist_test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFMDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'./FashionMNIST/fashion-mnist_train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#读取方式二:读入csv格式的数据，自行构建Dataset类\n",
    "#csv数据下载链接：https://www.kaggle.com/zalando-research/fashionmnist\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self,df,transform=None):#初始化\n",
    "        self.df=df\n",
    "        self.transform=transform\n",
    "        self.images=df.iloc[:,1:].values.astype(np.uint8)#提取对应子片段，unit8图片格式\n",
    "        self.labels=df.iloc[:,0].values\n",
    "    def __len__(self):#图片长度\n",
    "        return len(self.images)\n",
    "    def __getitem__(self,idx):#直接决定Dataset怎么构建\n",
    "        image=self.images[idx].reshape(28,28,1)#idx便是第几行\n",
    "        label=int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image=self.transform(image)  \n",
    "        else:\n",
    "            image=torch.tensor(image/255.,dtype=torch.float)\n",
    "        label=torch.tensor(label,dtype=torch.long)\n",
    "        return image,label\n",
    "train_df =pd.read_csv(\"./FashionMNIST/fashion-mnist_train.csv\")#我也不知到为啥File b'./FashionMNIST/fashion-mnist_train.csv' does not exist\n",
    "test_df =pd.read_csv('./FashionMNIST/fashion-mnist_test.csv')\n",
    "train_data=FMDataset(train_df,data_transform)\n",
    "test_data=FMDataset(test_df,data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3043e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "310a92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在构建训练和测试集完成后，需要定义DataLoader类，以使训练和测试时加载数据\n",
    "train_loader=DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=num_workers,drop_last=True)#说明train_data，batch_size每次输入数据数量，shuffle=True数据打乱，num_workers数据越大度的越快，drop_last=True最后一个要不要\n",
    "test_loader=DataLoader(test_data,batch_size=batch_size,shuffle=True,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b1397d",
   "metadata": {},
   "source": [
    "读入后，我们可以做一些可视化操作，主要是验证是否读入正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d3d8959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a7000c0438>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image,label=next(iter(train_loader))#迭代，\n",
    "print(image.shape,label.shape)\n",
    "plt.imshow(image[0][0],cmap='gray')#0是我们展示第零个数据，matplotlib.pyplot可视化\n",
    "#1是通道，28我们定义的\n",
    "#每次运行对train_loader进行一次操作，每次读到的不一样（出现说明读对了）\n",
    "\n",
    "#dataset和data_loader相结合，自己想读啥读啥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7dfa86",
   "metadata": {},
   "source": [
    "## 2.3.3模型构建\n",
    "- 神经网络的构建：基于nn.Module\n",
    "  __int__,forward\n",
    "- 神经网络是通过“层定义+层顺序”的方式构建起来的\n",
    "- 神经网络常见层\n",
    "  - nn.Conv2d, nn.MaxPool2d,nn.Linear, nn.ReLU,等\n",
    "- 代码演示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2eadee",
   "metadata": {},
   "source": [
    "模型设计：搭建一个CNN，而不考虑当下各种模型的复杂结构\n",
    "搭建完成，训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ee22f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):#继承\n",
    "    def __init__(self):#初始化\n",
    "        super(Net,self).__init__()#层定义\n",
    "        #Sequential惯序模型,按顺序\n",
    "        self.conv=nn.Sequential(\n",
    "           nn.Conv2d(1,32,5),#二维卷积  \n",
    "           nn.ReLU(),#激活函数\n",
    "           nn.MaxPool2d(2,stride=2),#池化？\n",
    "           nn.Dropout(0.3),# \n",
    "           nn.Conv2d(32,64,5),\n",
    "           nn.ReLU(),\n",
    "           nn.MaxPool2d(2,stride=2),\n",
    "           nn.Dropout(0,3)\n",
    "        )\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(64*4*4,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)#10是关键。输出类的个数\n",
    "        )\n",
    "    def forward(self,x):#前馈\n",
    "        x=self.conv(x)\n",
    "        x=x.view(-1,64*4*4)#拉平便于全连接层\n",
    "        x=self.fc(x)#把全连接层塞进来\n",
    "        #x=nn.functional.normalize(x)\n",
    "        return x\n",
    "model=Net()\n",
    "#model=model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b998f3",
   "metadata": {},
   "source": [
    "?nn.Conv2d来查看  哈哈哈这个好好用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "503d5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d42673",
   "metadata": {},
   "source": [
    "## 2.3.4损失函数\n",
    "- torch.nn提供了多种预定义的损失函数\n",
    "- 可以自己定义损失函数（二期）\n",
    "- 根据实际需求选用对应的损失函数\n",
    "- 损失函数常用操作\n",
    "  - backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1bbffd",
   "metadata": {},
   "source": [
    "## 设定损失函数\n",
    "  使用torch.nn模块自带的CrossEntropy损失\n",
    "  PyTorch会自动把整数型的label转化为one-hot型（不懂），用于计算ce loss\n",
    "  确保label是从0开始的，同时模型不加softmax层（使用logits计算）需要通盘考虑？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e98594",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "#criterion=nn.CrossEntropyLoss(weight=[1,1,1,2,1,1,1,1,1,1])#就是权重越大训练越好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cdf6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.CrossEntropyLoss\n",
    "#方便看策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36212353",
   "metadata": {},
   "source": [
    "## 2.3.5优化器\n",
    "- torch.optim提供了多种预定义的优化器\n",
    "- 自己定义优化器\n",
    "- 根据实际需求选择对应的损失函数\n",
    "- 优化器常用操作：\n",
    " - step(),zero_grad(),load_state_dict(),\n",
    "- 代码演示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3880df",
   "metadata": {},
   "source": [
    "定义优化器\n",
    "这里使用的Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33040322",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optimizer.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e229e",
   "metadata": {},
   "source": [
    "训练和测试（验证）\n",
    "各自封装成函数\n",
    "关注两者的主要区别\n",
    "- 模型需要初始化优化器\n",
    "- 是否需要loss 传回到网格\n",
    "- 是否需要每一步更新optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aad67478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss=0#loss初始化成0\n",
    "    for data,label in train_loader:#循环\n",
    "        #data,label=data.cuda(),laab.cuda()#如果数据放到gpu模型也要放上去\n",
    "        optimizer.zero_grad()#自动求导是会累加，这里初始化成零，放在loss.backword之前\n",
    "        output=model(data)#前向传播\n",
    "        loss=criterion(output,label)#损失函数\n",
    "        loss.backward()#反向传播会去（理论看一看）\n",
    "        optimizer.step()#优化器更新权重\n",
    "        train_loss+=loss.item()*data.size(0)\n",
    "    train_loss=train_loss/len(train_loader.dataset)#除以长度\n",
    "    print('Epoch:{}\\tTraining Loss:{:.6f}'.format(epoch,train_loss))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53cca618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#封装成函数测试和验证是不一样的，模式不一样1.模型定义的不同，2.优化器是否零初始化3.损失函数回传4.优化器要不要进行权重更新\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    val_loss=0\n",
    "    gt_labels=[]\n",
    "    pred_labels=[]\n",
    "    with torch.no_grad():#不做梯度计算\n",
    "        for data,label in test_loader:\n",
    "             #data,label=data.cuda(),laab.cuda()#如果数据放到gpu模型也要放上去\n",
    "                output=model(data)\n",
    "                preds=torch.argmax(output,1)\n",
    "                gt_labels.append(preds.cpu().data.numpy())#不太一样\n",
    "                pred_labels.append(preds.cpu().data.numpy())\n",
    "                loss=criterion(output,label)#损失不回传\n",
    "                val_loss += loss.item()*data.size(0)\n",
    "    val_loss=val_loss/len(test_loader.dataset)\n",
    "    gt_labels,pre_labels=np.concatenate(gt_labels),np.concatenate(pred_labels)\n",
    "    acc=np.sum(gt_labels==pred_labels)/len(pred_labels)#计算指标准确率\n",
    "    print('Epoch:{}\\tValidatation Loss:{:.6f},Accuracy:{:6f}'.format(epoch,val_loss,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd53ed3",
   "metadata": {},
   "source": [
    "## 2.3.6训练与评估\n",
    "- 模型状态设置\n",
    " - model.train(),model.evel()\n",
    "- 训练流程：读取、转换、梯度清零、输入、计算损失、反向传播、参数更新\n",
    "- 验证流程：读取、转换、输入、计算损失、计算指标\n",
    "- 代码演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d0a4bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\tTraining Loss:0.346045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "D:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\tValidatation Loss:0.329297,Accuracy:0.000000\n",
      "Epoch:2\tTraining Loss:0.308294\n",
      "Epoch:2\tValidatation Loss:0.309265,Accuracy:0.000000\n",
      "Epoch:3\tTraining Loss:0.283029\n",
      "Epoch:3\tValidatation Loss:0.286054,Accuracy:0.000000\n",
      "Epoch:4\tTraining Loss:0.262746\n",
      "Epoch:4\tValidatation Loss:0.277277,Accuracy:0.000000\n",
      "Epoch:5\tTraining Loss:0.247704\n",
      "Epoch:5\tValidatation Loss:0.266038,Accuracy:0.000000\n",
      "Epoch:6\tTraining Loss:0.236856\n",
      "Epoch:6\tValidatation Loss:0.261052,Accuracy:0.000000\n",
      "Epoch:7\tTraining Loss:0.220864\n",
      "Epoch:7\tValidatation Loss:0.249717,Accuracy:0.000000\n",
      "Epoch:8\tTraining Loss:0.209909\n",
      "Epoch:8\tValidatation Loss:0.238019,Accuracy:0.000000\n",
      "Epoch:9\tTraining Loss:0.200130\n",
      "Epoch:9\tValidatation Loss:0.242086,Accuracy:0.000000\n",
      "Epoch:10\tTraining Loss:0.190781\n",
      "Epoch:10\tValidatation Loss:0.232178,Accuracy:0.000000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,epochs+1):#开始训练\n",
    "    train(epoch)\n",
    "    val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d532aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU可以用\n",
    "gpu_info=!nvidia-smi-i 0\n",
    "gpu_info='\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd02a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型保存\n",
    "save_path='./FashionModel.pkl'\n",
    "torch.save(model,save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
