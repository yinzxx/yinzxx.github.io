{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c73f08d",
   "metadata": {},
   "source": [
    "## 第一部分：PyTorch深度学习基础知识\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9d783",
   "metadata": {},
   "source": [
    "### 2.2深度学习在实现上的特殊性\n",
    "- 样本量大，通常需要分批（bath）加载\n",
    "- 逐层、模板化搭建网络（卷积层、全连接、LSTM等）\n",
    "- 多样化的损失函数和优化器设计*\n",
    "- GPU的使用\n",
    "- 模块间配合\n",
    "\n",
    "## 2.3PyTorch深度学习模块\n",
    "- 世纪使用根据需要进行修改\n",
    "- 深度学习：搭积木\n",
    "  - 2.3.1基本配置\n",
    "  - 2.3.2数据读入\n",
    "  - 2.3.3模型构建\n",
    "  - 2.3.4损失函数\n",
    "  - 2.3.5优化器\n",
    "  - 2.3.6优化与评估\n",
    "- 边学边练，通过实战案例巩固\n",
    "- 任务：FashionMNIST时装分类\n",
    "- 数据简介：\n",
    "  - 10类图片\n",
    "  - 32*32px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc2194",
   "metadata": {},
   "source": [
    "### 2.\n",
    "- 导入必要的packages\n",
    " - os ,numpy, pandas, torch, torch.nn,torch.optin, torch.utils.data\n",
    "- 配置训练过程中的超参数\n",
    " - batch size,learning rate,max_epochs,num_workers\n",
    "- 配置训练用的硬件设备\n",
    " - cpu ,GPU,\n",
    "- 代码演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6bb457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导包\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8411a9",
   "metadata": {},
   "source": [
    "#### 配置训练环境和超参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a64812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置GPU,这里有两种方式\n",
    "## 一：os.environ\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='0'#这里的0就是第一块显卡\n",
    "# 二：使用“device”,后续对要使用GPU的变量.to(device)即可\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "## 配置其他超参数，batch size,learning rate,max_epochs,num_workers\n",
    "batch_size=256#每次训练数据的量\n",
    "num_workers=4#有多少个线程\n",
    "lr=1e-4#learn rate 每次更新步长\n",
    "epochs=20#总的epochs 训练多少轮\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45963756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.is_available()#我用的cpu版本，emm小的模型也是可以跑的，大家最好下载GPU版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36eff185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "image_size=28\n",
    "data_transform=transforms.Compose([\n",
    "   # transforms.ToPILImage(),\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edbd6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取方式一\n",
    "from torchvision import datasets\n",
    "train_data = datasets.FashionMNIST(root= './',train=True,download=True,transform=data_transform)#train_data是训练集\n",
    "test_data = datasets.FashionMNIST(root='./',train=False,download=True,transform=data_transform)#test_data是测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "- PyTorch数据读入是通过Dataset+DataLoader的方式完成的，Dataset定义好数据的格式和数据变换形式，DataLoader用iterative的方式不断读入批次数据。\n",
    "\n",
    "  我们可以定义自己的Dataset类来实现灵活的数据读取，定义的类需要继承PyTorch自身的Dataset类。主要包含三个函数：\n",
    "\n",
    "  - __init__: 用于向类中传入外部参数，同时定义样本集\n",
    "\n",
    "  - __getitem__: 用于逐个读取样本集合中的元素，可以进行一定的变换，并将返回训练/验证所需的数据\n",
    "\n",
    "  - __len__: 用于返回数据集的样本数\n",
    "\n",
    "   下面以cifar10数据集为例给出构建Dataset类的方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b7835ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./FashionMNIST/fashion-mnist_train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-bc430605ec2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./FashionMNIST/fashion-mnist_train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./FashionMNIST/fashion-mnist_test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFMDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Minicoda3\\Minicoda3-4.7.10\\envs\\gluon\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'./FashionMNIST/fashion-mnist_train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#读取方式二:读入csv格式的数据，自行构建Dataset类\n",
    "#csv数据下载链接：https://www.kaggle.com/zalando-research/fashionmnist\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self,df,transform=None):#初始化\n",
    "        self.df=df\n",
    "        self.transform=transform\n",
    "        self.images=df.iloc[:,1:].values.astype(np.uint8)#提取对应子片段，unit8图片格式\n",
    "        self.labels=df.iloc[:,0].values\n",
    "    def __len__(self):#图片长度\n",
    "        return len(self.images)\n",
    "    def __getitem__(self,idx):#直接决定Dataset怎么构建\n",
    "        image=self.images[idx].reshape(28,28,1)#idx便是第几行\n",
    "        label=int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image=self.transform(image)  \n",
    "        else:\n",
    "            image=torch.tensor(image/255.,dtype=torch.float)\n",
    "        label=torch.tensor(label,dtype=torch.long)\n",
    "        return image,label\n",
    "train_df =pd.read_csv(\"./FashionMNIST/fashion-mnist_train.csv\")#我也不知到为啥File b'./FashionMNIST/fashion-mnist_train.csv' does not exist\n",
    "test_df =pd.read_csv('./FashionMNIST/fashion-mnist_test.csv')\n",
    "train_data=FMDataset(train_df,data_transform)\n",
    "test_data=FMDataset(test_df,data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf47a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8cac840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在构建训练和测试集完成后，需要定义DataLoader类，以使训练和测试时加载数据\n",
    "train_loader=DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=num_workers,drop_last=True)#说明train_data，batch_size每次输入数据数量，shuffle=True数据打乱，num_workers数据越大度的越快，drop_last=True最后一个要不要\n",
    "test_loader=DataLoader(test_data,batch_size=batch_size,shuffle=True,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d410978",
   "metadata": {},
   "source": [
    "读入后，我们可以做一些可视化操作，主要是验证是否读入正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed58642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b7614e2ac8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image,label=next(iter(train_loader))#迭代，\n",
    "print(image.shape,label.shape)\n",
    "plt.imshow(image[0][0],cmap='gray')#0是我们展示第零个数据，matplotlib.pyplot可视化\n",
    "#1是通道，28我们定义的\n",
    "#每次运行对train_loader进行一次操作，每次读到的不一样（出现说明读对了）\n",
    "\n",
    "#dataset和data_loader相结合，自己想读啥读啥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e44dabf",
   "metadata": {},
   "source": [
    "## 2.3.3模型构建\n",
    "- 神经网络的构建：基于nn.Module\n",
    "  __int__,forward\n",
    "- 神经网络是通过“层定义+层顺序”的方式构建起来的\n",
    "- 神经网络常见层\n",
    "  - nn.Conv2d, nn.MaxPool2d,nn.Linear, nn.ReLU,等\n",
    "- 代码演示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e054dd1",
   "metadata": {},
   "source": [
    "模型设计：搭建一个CNN，而不考虑当下各种模型的复杂结构\n",
    "搭建完成，训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41962bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):#继承\n",
    "    def __init__(self):#初始化\n",
    "        super(Net,self).__init__()#层定义\n",
    "        #Sequential惯序模型,按顺序\n",
    "        self.conv=nn.Sequential(\n",
    "           nn.Conv2d(1,32,5),#二维卷积  \n",
    "           nn.ReLU(),#激活函数\n",
    "           nn.MaxPool2d(2,stride=2),#池化？\n",
    "           nn.Dropout(0.3),# \n",
    "           nn.Conv2d(32,64,5),\n",
    "           nn.ReLU(),\n",
    "           nn.MaxPool2d(2,stride=2),\n",
    "           nn.Dropout(0,3)\n",
    "        )\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(64*4*4,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)#10是关键。输出类的个数\n",
    "        )\n",
    "    def forward(self,x):#前馈\n",
    "        x=self.conv(x)\n",
    "        x=x.view(-1,64*4*4)#拉平便于全连接层\n",
    "        x=self.fc(x)#把全连接层塞进来\n",
    "        #x=nn.functional.normalize(x)\n",
    "        return x\n",
    "model=Net()\n",
    "#model=model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad24b7",
   "metadata": {},
   "source": [
    "?nn.Conv2d来查看  哈哈哈这个好好用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3b0d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36372a9a",
   "metadata": {},
   "source": [
    "## 2.3.4损失函数\n",
    "- torch.nn提供了多种预定义的损失函数\n",
    "- 可以自己定义损失函数（二期）\n",
    "- 根据实际需求选用对应的损失函数\n",
    "- 损失函数常用操作\n",
    "  - backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf723f0a",
   "metadata": {},
   "source": [
    "## 设定损失函数\n",
    "  使用torch.nn模块自带的CrossEntropy损失\n",
    "  PyTorch会自动把整数型的label转化为one-hot型（不懂），用于计算ce loss\n",
    "  确保label是从0开始的，同时模型不加softmax层（使用logits计算）需要通盘考虑？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc966620",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "#criterion=nn.CrossEntropyLoss(weight=[1,1,1,2,1,1,1,1,1,1])#就是权重越大训练越好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "742d0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.CrossEntropyLoss\n",
    "#方便看策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd67b8",
   "metadata": {},
   "source": [
    "## 2.3.5优化器\n",
    "- torch.optim提供了多种预定义的优化器\n",
    "- 自己定义优化器\n",
    "- 根据实际需求选择对应的损失函数\n",
    "- 优化器常用操作：\n",
    " - step(),zero_grad(),load_state_dict(),\n",
    "- 代码演示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1486a13",
   "metadata": {},
   "source": [
    "定义优化器\n",
    "这里使用的Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "151ced1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optimizer.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50453a1f",
   "metadata": {},
   "source": [
    "训练和测试（验证）\n",
    "各自封装成函数\n",
    "关注两者的主要区别\n",
    "- 模型需要初始化优化器\n",
    "- 是否需要loss 传回到网格\n",
    "- 是否需要每一步更新optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9534eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train.loss=0#loss初始化成0\n",
    "    for data,label in train_loader:#循环\n",
    "        #data,label=data.cuda(),laab.cuda()#如果数据放到gpu模型也要放上去\n",
    "        optimizer.zero_grad()#自动求导是会累加，这里初始化成零，放在loss.backword之前\n",
    "        output=model(data)#前向传播\n",
    "        loss=criterion(output,label)#损失函数\n",
    "        loss.backward()#反向传播会去（理论看一看）\n",
    "        optimizer.step()#优化器更新权重\n",
    "        train_loss+=loss.item()*data.size(0)\n",
    "    train_loss=train_loss/len(train_loader.dataset)#除以长度\n",
    "    print('Epoch:{}\\tTraining Loss:{:.6f}'.format(epoch,train_loss))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52044ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#封装成函数测试和验证是不一样的，模式不一样\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    val_loss()=0\n",
    "    gt_labels=[]\n",
    "    pred_labels=[]\n",
    "    with torch.no_grad():#不做梯度计算\n",
    "        for data,label in test_loader:\n",
    "             #data,label=data.cuda(),laab.cuda()#如果数据放到gpu模型也要放上去\n",
    "                outup=model(data)\n",
    "                preds=torch.argmax(output,1)\n",
    "                gt_labels.append(preds.cpu().data.numpy())#不太一样\n",
    "                pred_labels.append(preds.cpu().data.numpy())\n",
    "                loss=criterion(output,label)#损失不回传\n",
    "                val_loss+=loss.item*data.size(0)\n",
    "            val_loss=val_loss/len(test_loader.dataset)\n",
    "            gt_labels,pre_labels=np.concatenate(gt_labels),np.concatenate(pred_labels)\n",
    "            acc=np.sum(gt_labels==pred_lanles)/len(pred_labels)#准确率\n",
    "            print('Epoch:{}\\tValidatation Loss:{:.6f},Accuracy:{:6f}'.format(epoch,val_loss,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffbab0f",
   "metadata": {},
   "source": [
    "## 2.3.6训练与评估\n",
    "- 模型状态设置\n",
    " - model.train(),model.evel()\n",
    "- 训练流程：读取、转换、梯度清零、输入、计算损失、反向传播、参数更新\n",
    "- 验证流程：读取、转换、输入、计算损失、计算指标\n",
    "- 代码演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f53e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
