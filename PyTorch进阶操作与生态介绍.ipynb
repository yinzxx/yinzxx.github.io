{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b8c1abb",
   "metadata": {},
   "source": [
    "第二部分：PyTorch(进阶)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb067349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2a456",
   "metadata": {},
   "source": [
    "Point1:模型定义方式\n",
    "PyTorch中自定义模型主要通过一下三种方式\n",
    "- Sequential\n",
    "- ModuleList\n",
    "- ModuleDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45e90e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#讲解点：使用ordered dict更有助于一目了然模型结构，对于之后的模型修改也非常有帮助\n",
    "##Sequential:Direct list(直接列出来)两种定义方式\n",
    "import torch.nn as nn\n",
    "net1=nn.Sequential(#做一个两层神经网络\n",
    "       nn.Linear(784,256),#输入为784\n",
    "       nn.ReLU(),#损失函数\n",
    "       nn.Linear(256,10),\n",
    "       )\n",
    "print(net1)#两个Linear的映射层，一个Relu激活层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95162e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fcl): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relul): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "##Sequential:Ordered Dict#带顺序的字典\n",
    "import collections\n",
    "import torch.nn as nn\n",
    "net2=nn.Sequential(collections.OrderedDict([\n",
    "       ('fcl',nn.Linear(784,256)),\n",
    "       ('relul',nn.ReLU()),\n",
    "       ('fc2',nn.Linear(256,10))\n",
    "       ]))\n",
    "print(net2)\n",
    "#两个一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50cee2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "#试一下\n",
    "a=torch.rand(4,784)#随机产生一个tensor\n",
    "out1=net1(a)#输出结果\n",
    "out2=net2(a)\n",
    "print(out1.shape==out2.shape,out1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cad7122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=256, out_features=10, bias=True)\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#ModuleList\n",
    "net3=nn.ModuleList([nn.Linear(784,256),nn.ReLU()])\n",
    "net3.append(nn.Linear(256,10))#类似list的append操作\n",
    "print(net3[-1])\n",
    "print(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "995bb99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#注意ModuleList 并没有定义一个网络，他只是将不同的模块储存在一起，此处此处应报错\n",
    "#out3=net3(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1afddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self):#先初始化\n",
    "        super().__init__()#利用初始化定义模型层\n",
    "        self.modulelist=nn.ModuleList([nn.Linear(784,256),nn.ReLU()])\n",
    "        self.modulelist.append(nn.Linear(256,10))\n",
    "    def forward(self,x):#得到前向传播的关系\n",
    "        for layer in self.modulelist:\n",
    "            x=layer(x)\n",
    "        return x\n",
    "net3_ = Net3()\n",
    "out3_ = net3_(a)\n",
    "print(out3_.shape)#得到结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44a049c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#ModuleDict\n",
    "net4=nn.ModuleDict({#做一个两层神经网络\n",
    "       'linear':nn.Linear(784,256),#输入为784\n",
    "       'act':nn.ReLU(),#损失函数\n",
    "})\n",
    "net4['output']=nn.Linear(256,10)#添加第三层\n",
    "print(net4['linear'])\n",
    "print(net4.output)#两个Linear的映射层，一个Relu激活层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8239434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#同样的，ModuleDict并没有定义一个网络，他只是将不同的模块储存在一起，此处应报错\n",
    "#正确使用的方法同上\n",
    "out4=net(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a557b",
   "metadata": {},
   "source": [
    "## 利用模块快速搭建复炸网路\n",
    "      快速构建U-Net\n",
    "      定义好几个模块，然后串起来，模块可以复用，U-Net每一个小块都有两次卷积的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e3670c",
   "metadata": {},
   "source": [
    "组成U-Net的模型主要包括：\n",
    "- 每个子块内部的两次卷积（Double Convolution)\n",
    "- 左侧模型块之间的下采样链接，及最大池化（Max pooling）\n",
    "- 右侧模型块之间的上采样连接（Up sampling）\n",
    "- 输出层的处理\n",
    "      除模型块外，还有模型块之间的，横向链接，输入和U-Net底部的链接计算，通过forward实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0013cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8b2d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):#双次卷积\n",
    "    '''(convolution =>[BN]>=ReLU) *2'''\n",
    "    def __init__(self,in_channels,out_channels,mid_channels=None):#三个通道\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels=out_channels\n",
    "        self.double_conv=nn.Sequential(\n",
    "            nn.Conv2d(in_channels,mid_channels,kernel_size=3,padding=1,bias=False),#第一次卷积\n",
    "            nn.BatchNorm1d(mid_channels),#忘了这是干啥来着\n",
    "            nn.ReLU(inplace=True),#激活\n",
    "            nn.Conv2d(mid_channels,out_channels,kernel_size=3,padding=1,bias=False),#第二次卷积\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Down(nn.Module):\n",
    "    '''Downscaling with maxpool then double conv'''\n",
    "    def __init__(self,in_channel,out_channels):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up(nn.Module):\n",
    "    '''UPscaling then don=uble conv'''\n",
    "    def __init__(self,in_channel,out_channels,bilinear=True):\n",
    "        super.maxpool_conv=nn.Sequential(\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
